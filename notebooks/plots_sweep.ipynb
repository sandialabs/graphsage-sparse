{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cfcbac-7078-4d5d-a1aa-1f9d03c57bad",
   "metadata": {},
   "source": [
    "# A100 Parameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c149e-01b9-4e67-8817-63beeb986c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252aefb-837a-46e6-b736-d1790bb8c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    total_time = np.nan\n",
    "    warmup_time = np.nan\n",
    "    mean_time = np.nan\n",
    "    total_steps = np.nan\n",
    "    test_metric = np.nan\n",
    "    loss = np.array([])\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line.startswith('total time:'):\n",
    "                total_time = float(line.split(':')[1].split('s')[0].strip())\n",
    "            elif line.startswith('warmup time:'):\n",
    "                warmup_time = float(line.split(':')[1].split('s')[0].strip())\n",
    "            elif line.startswith('mean post time:'):\n",
    "                mean_time = float(line.split(':')[1].split('s')[0].strip())\n",
    "            elif line.startswith('total steps:'):\n",
    "                total_steps = int(line.split(':')[1].strip())\n",
    "            elif line.startswith('test'):\n",
    "                test_metric = float(line.split(':')[1].strip())\n",
    "            elif line.startswith('loss'):\n",
    "                loss_arr = line.split(':')[1].strip().split(',')\n",
    "                loss = np.array([float(_) for _ in loss_arr])\n",
    "    record = {'total time':total_time, 'warmup time':warmup_time,\n",
    "              'mean time':mean_time, 'total steps':total_steps,\n",
    "              'score':test_metric}\n",
    "    return record, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da6c5d-a982-4fd3-b609-cebd634e422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_records(dataset, algorithms, max_degrees, batch_sizes, agg_dims, sample_sizes):\n",
    "    records = []\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    algs = []\n",
    "    ms = []\n",
    "    bs = []\n",
    "    ads = []\n",
    "    ss = []\n",
    "    for a in algorithms:\n",
    "        for m in max_degrees:\n",
    "            for b in batch_sizes:\n",
    "                for ad in agg_dims:\n",
    "                    for s in sample_sizes:\n",
    "                        filename = '../output/%s_a_%s_b_%d_ad_%d_m_%d_s_%d.out.txt'%(\n",
    "                            dataset, a, b, ad, m, s)\n",
    "                        record, loss = parse_file(filename)\n",
    "                        record['algorithm'] = a\n",
    "                        record['max degree'] = m\n",
    "                        record['batch size'] = b\n",
    "                        record['agg dim'] = ad\n",
    "                        record['sample size'] = s\n",
    "                        records.append(record)\n",
    "                        losses.append(loss)\n",
    "                        epochs.append(np.arange(len(losses[-1])))\n",
    "                        algs.append(np.repeat(a, len(losses[-1])))\n",
    "                        ms.append(np.repeat(m, len(losses[-1])))\n",
    "                        bs.append(np.repeat(b, len(losses[-1])))\n",
    "                        ads.append(np.repeat(ad, len(losses[-1])))\n",
    "                        ss.append(np.repeat(s, len(losses[-1])))\n",
    "    losses = np.log(np.concatenate(losses))\n",
    "    epochs = np.concatenate(epochs)\n",
    "    algs = np.concatenate(algs)\n",
    "    ms = np.concatenate(ms)\n",
    "    bs = np.concatenate(bs)\n",
    "    ads = np.concatenate(ads)\n",
    "    ss = np.concatenate(ss)\n",
    "    ldf = pd.DataFrame({'epoch':epochs, 'loss':losses,\n",
    "                        'max degree':ms, 'algorithm':algs,\n",
    "                        'batch size':bs, 'agg dim':ads,\n",
    "                        'sample size':ss})\n",
    "    rdf = pd.DataFrame(records)\n",
    "\n",
    "    return ldf, rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3bd18-6c65-4632-b290-ffad412524a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(ldf, title, hue='algorithm', style='max degree'):\n",
    "    gr = (np.sqrt(5)-1)/2  # golden ratio\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, gr*8))\n",
    "    ax = sns.lineplot(x='epoch', y='loss', hue=hue, \n",
    "                      style=style, data=ldf, \n",
    "                      palette=sns.color_palette(\n",
    "                          'hls', len(ldf[hue].unique())))\n",
    "    plt.xlabel('epoch', fontsize=14)\n",
    "    plt.ylabel('log loss', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.legend(bbox_to_anchor=(1.01,1), fontsize=14)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130645bb-0be0-4228-b0ac-beaab2d00a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_bars(rdf, title, x='max degree', hue='algorithm'):\n",
    "    gr = (np.sqrt(5)-1)/2 # golden ratio\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, gr*8))\n",
    "    ax = sns.barplot(x=x, y='mean time', hue=hue, \n",
    "                     data=rdf,  palette=sns.color_palette(\n",
    "                         'hls', len(ldf[hue].unique())))\n",
    "    plt.xlabel(x, fontsize=14)\n",
    "    plt.ylabel('time (s)', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    # for some reason ax.legend() isn't working here\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='14')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c08382-497a-4802-8ef9-90b7f139e3f4",
   "metadata": {},
   "source": [
    "### BTER (Unsup) - Batch Size/Agg Dim\n",
    "```\n",
    "n=1\n",
    "d='bter'\n",
    "p='gpu'\n",
    "a='dense'\n",
    "bs=(128 512 1024)\n",
    "e=5\n",
    "ads=(256 512 1024)\n",
    "de=2\n",
    "m=100\n",
    "nss=5\n",
    "s=15\n",
    "do=.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe124b-124a-45df-8709-15d30b8dad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'bter'\n",
    "algorithms = ['dense']\n",
    "batch_sizes = [128, 512, 1024]\n",
    "agg_dims = [256, 512, 1024]\n",
    "max_degrees = [100]\n",
    "sample_sizes = [15]\n",
    "ldf, rdf = parse_records(dataset, algorithms, max_degrees, batch_sizes, agg_dims, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4438498-d64d-42e4-a42e-e4b242aeb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(ldf, 'BTER - Dense, Batch/Agg Sweep (A100)', hue='batch size', style='agg dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3abb7-d7a7-467d-944e-c39be72c8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_bars(rdf, 'BTER - Dense, Batch/Agg Sweep (A100)', x='batch size', hue='agg dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353a0ac-a91f-4506-a99c-f986d4f6eb29",
   "metadata": {},
   "source": [
    "### REDDIT (Unsup) - Batch Size/Agg Dim\n",
    "```\n",
    "n=1\n",
    "d='lreddit'\n",
    "p='gpu'\n",
    "a='dense'\n",
    "bs=(256 512 1024)\n",
    "e=5\n",
    "ads=(128 512 1024)\n",
    "de=2\n",
    "m=128\n",
    "nss=5\n",
    "s=15\n",
    "do=.5\n",
    "pt=.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e3fbc-5767-43b6-8c9a-d5a3f7869a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'lreddit'\n",
    "algorithms = ['dense']\n",
    "batch_sizes = [256, 512, 1024]\n",
    "agg_dims = [128, 512, 1024]\n",
    "max_degrees = [128]\n",
    "sample_sizes = [15]\n",
    "ldf, rdf = parse_records(dataset, algorithms, max_degrees, batch_sizes, agg_dims, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28752cb2-b159-4fd8-9120-85e095c1ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(ldf, 'REDDIT (Unsup) - Dense, Batch/Agg Sweep (A100)', hue='batch size', style='agg dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf542f0d-9e3d-44cf-9619-1d24d8e66f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_bars(rdf, 'REDDIT (Unsup) - Dense, Batch/Agg Sweep (A100)', x='batch size', hue='agg dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401adda6-a818-4834-9b4b-b981f1683eae",
   "metadata": {},
   "source": [
    "### OGB-ARXIV (Sup) - Batch Size/Agg Dim\n",
    "```\n",
    "n=1\n",
    "d='arxiv'\n",
    "p='gpu'\n",
    "a='dense'\n",
    "bs=(128 512 1024)\n",
    "e=200\n",
    "ads=(256 512 1024)\n",
    "de=2\n",
    "m=100\n",
    "s=15\n",
    "pa=20\n",
    "do=.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bffa3-958f-4e72-a672-b29fa783b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'arxiv'\n",
    "algorithms = ['dense']\n",
    "batch_sizes = [128, 512, 1024]\n",
    "agg_dims = [256, 512, 1024]\n",
    "max_degrees = [100]\n",
    "sample_sizes = [15]\n",
    "ldf, rdf = parse_records(dataset, algorithms, max_degrees, batch_sizes, agg_dims, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a9c46-7c79-46d9-ba7e-96a538a3571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(ldf, 'ARXIV - Dense, Batch/Agg Sweep (A100)', hue='batch size', style='agg dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc854a-8190-4dd4-a611-14e8c05e179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_bars(rdf, 'ASRXIV - Dense, Batch/Agg Sweep (A100)', x='batch size', hue='agg dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196faee5-94f5-4db7-9046-c59b6b160084",
   "metadata": {},
   "source": [
    "### Reddit (sup) - Batch Size/Agg Dim\n",
    "```\n",
    "n=1\n",
    "d='nreddit'\n",
    "p='gpu'\n",
    "a='dense'\n",
    "bs=(256 512 1024)\n",
    "e=200\n",
    "ads=(128 512 1024)\n",
    "de=2\n",
    "m=128\n",
    "s=15\n",
    "pa=20\n",
    "do=.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ec03a-c3b0-4f8c-a41e-f05482f5f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'nreddit'\n",
    "algorithms = ['dense']\n",
    "batch_sizes = [256, 512, 1024]\n",
    "agg_dims = [128, 512, 1024]\n",
    "max_degrees = [128]\n",
    "sample_sizes = [15]\n",
    "ldf, rdf = parse_records(dataset, algorithms, max_degrees, batch_sizes, agg_dims, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170230b-3993-421a-acf7-ffef59d6bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(ldf, 'REDDIT (Sup) - Dense, Batch/Agg Sweep (A100)', hue='batch size', style='agg dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e537c4-980e-45cc-ae8c-be27de74c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_bars(rdf, 'REDDIT (Sup) - Dense, Batch/Agg Sweep (A100)', x='batch size', hue='agg dim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariaa",
   "language": "python",
   "name": "ariaa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
